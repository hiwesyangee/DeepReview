1.熟悉Java和scala编程，熟悉面向对象编程、多线程与高并发，熟悉常用数据结构与算法；										4天。比较重点。
2.熟练使用Spark三大组件SQL、Streaming、MLlib，掌握机器学习常见算法，如：聚类、分类、回归、协同过滤、关联规则、降维等；	    7天。重中之重！！！
3.熟悉推荐系统数据建模，掌握ALS算法并针对模型结果进行评估与常规优化；												    4天。重点！
4.熟悉Hadoop生态各组件，如：Hadoop、HDFS、HBase、Zookeeper、Sqoop等，掌握hbase数据库的高性能批量读写优化；			    2天。之后找时间。
5.熟悉Hbase Rowkey的散列与预分区设计，解决HBase的热点问题和数据倾斜问题，数据库的容灾与备份；							3天。重点！
6.熟悉数据实时处理流程，掌握flume+kafka数据采集和消息队列组件；														1天。抽时间。
7.熟练使用ElasticStack各组件，掌握ES进行数据与日志分析，构建搜索引擎并进行常规优化；									7天。比较重点。
8.熟悉Redis和MySQL数据库的操作、使用和常规优化，掌握常用SQL语句；													3天。之后找时间。
9.熟练使用ClouderaManager与Ambari进行大数据集群快速部署及二次开发；												    2天。抽时间。
10.熟悉Linux操作系统及常用Shell命令的使用；																		2天。抽时间。
11.熟练使用IDEA、Git、Maven项目管理和项目构建工具；																1天。之后找时间。
																											共计：36天，预备40天。4月1号。
